<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>详解Java中4种IO模型</title>
      <link href="/posts/8c27.html"/>
      <url>/posts/8c27.html</url>
      
        <content type="html"><![CDATA[<p>同步、异步、阻塞、非阻塞都是和I/O（输入输出）有关的概念，最简单的文件读取就是I/O操作。而在文件读取这件事儿上，可以有多种方式。</p><p>本篇会先介绍一下I/O的基本概念，通过一个生活例子来分别解释下这几种I/O模型，以及Java支持的I/O模型。</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>在解释I/O模型之前，我先说明一下几个操作系统的概念</p><h3 id="文件描述符fd"><a href="#文件描述符fd" class="headerlink" title="文件描述符fd"></a>文件描述符fd</h3><p>文件描述符（file descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。</p><p>文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。 当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。 在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。</p><h3 id="缓存I-O"><a href="#缓存I-O" class="headerlink" title="缓存I/O"></a>缓存I/O</h3><p>缓存I/O又被称作标准I/O，大多数文件系统的默认I/O操作都是缓存I/O。在Linux的缓存I/O机制中， 操作系统会将I/O的数据缓存在文件系统的页缓存中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中， 然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。</p><p>缓存I/O的缺点是数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的CPU以及内存开销是非常大的。</p><p>下面我以一个生活中烧开水的例子来形象解释一下同步、异步、阻塞、非阻塞概念。</p><h3 id="同步和异步"><a href="#同步和异步" class="headerlink" title="同步和异步"></a>同步和异步</h3><p>说到烧水，我们都是通过热水壶来烧水的。在很久之前，科技还没有这么发达的时候，如果我们要烧水， 需要把水壶放到火炉上，我们通过观察水壶内的水的沸腾程度来判断水有没有烧开。</p><p>随着科技的发展，现在市面上的水壶都有了提醒功能，当我们把水壶插电之后，水壶水烧开之后会通过声音提醒我们水开了。</p><p>对于烧水这件事儿来说，传统水壶的烧水就是同步的，高科技水壶的烧水就是异步的。</p><p><strong>同步请求</strong></p><p>A调用B，B的处理是同步的，在处理完之前他不会通知A，只有处理完之后才会明确的通知A。</p><p><strong>异步请求</strong></p><p>A调用B，B的处理是异步的，B在接到请求后先告诉A我已经接到请求了，然后异步去处理，处理完之后通过回调等方式再通知A。</p><p>所以说，同步和异步最大的区别就是被调用方的执行方式和返回时机。 同步指的是被调用方做完事情之后再返回，异步指的是被调用方先返回，然后再做事情，做完之后再想办法通知调用方。</p><h3 id="阻塞和非阻塞"><a href="#阻塞和非阻塞" class="headerlink" title="阻塞和非阻塞"></a>阻塞和非阻塞</h3><p>还是那个烧水的例子，当你把水放到水壶里面，按下开关后，你可以坐在水壶前面，别的事情什么都不做， 一直等着水烧好。你还可以先去客厅看电视，等着水开就好了。</p><p>对于你来说，坐在水壶前面等就是阻塞的，去客厅看电视等着水开就是非阻塞的。</p><p><strong>阻塞请求</strong></p><p>A调用B，A一直等着B的返回，别的事情什么也不干。</p><p><strong>非阻塞请求</strong></p><p>A调用B，A不用一直等着B的返回，先去忙别的事情了。</p><p>所以说，阻塞和非阻塞最大的区别就是在被调用方返回结果之前的这段时间内，调用方是否一直等待。 阻塞指的是调用方一直等待别的事情什么都不做。非阻塞指的是调用方先去忙别的事情。</p><h3 id="阻塞、非阻塞和同步、异步的区别"><a href="#阻塞、非阻塞和同步、异步的区别" class="headerlink" title="阻塞、非阻塞和同步、异步的区别"></a>阻塞、非阻塞和同步、异步的区别</h3><p>首先，前面已经提到过，阻塞、非阻塞和同步、异步其实针对的对象是不一样的。</p><p>给我大声念三遍下面的句子</p><p><em>阻塞、非阻塞说的是调用者。同步、异步说的是被调用者。</em></p><p><em>阻塞、非阻塞说的是调用者。同步、异步说的是被调用者。</em></p><p><em>阻塞、非阻塞说的是调用者。同步、异步说的是被调用者。</em></p><p>有人认为阻塞和同步是一回事儿，非阻塞和异步是一回事。但是这是不对的。</p><p><strong>同步包含阻塞和非阻塞</strong></p><p>我们是用传统的水壶烧水。在水烧开之前我们一直做在水壶前面，等着水开。这就是阻塞的。</p><p>我们是用传统的水壶烧水。在水烧开之前我们先去客厅看电视了，但是水壶不会主动通知我们， 需要我们时不时的去厨房看一下水有没有烧开，这就是非阻塞的。</p><p><strong>异步包含阻塞和非阻塞</strong></p><p>我们是用带有提醒功能的水壶烧水。在水烧发出提醒之前我们一直做在水壶前面，等着水开。这就是阻塞的。</p><p>我们是用带有提醒功能的水壶烧水。在水烧发出提醒之前我们先去客厅看电视了，等水壶发出声音提醒我们。这就是非阻塞的。推荐阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;mid=2247488012&amp;idx=2&amp;sn=26f74339024d342b81c0957d839979ee&amp;chksm=eb53973adc241e2c35c58b55d5a7962d56bc2db0f02ebf8b4c910764369fd8ccc55e2ba6eefd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">46 道阿里巴巴 Java 面试题，你会几道？</a></p><h2 id="Unix中的五种I-O模型"><a href="#Unix中的五种I-O模型" class="headerlink" title="Unix中的五种I/O模型"></a>Unix中的五种I/O模型</h2><p>对于一次I/O访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 所以说，当一个read操作发生时，它会经历两个阶段：</p><p>第一阶段：等待数据准备 (Waiting for the data to be ready)。</p><p>第二阶段：将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)。</p><p><strong>对于socket流而言</strong></p><p>第一阶段：通常涉及等待网络上的数据分组到达，也就是被复制到内核的某个缓冲区。</p><p>第二阶段：把数据从内核缓冲区复制到应用进程缓冲区。</p><p><strong>Unix下五种I/O模型：</strong></p><ol><li>同步阻塞I/O</li><li>同步非阻塞I/O</li><li>I/O多路复用（select和poll）</li><li>信号驱动I/O（SIGIO）</li><li>异步非阻塞 IO</li></ol><h3 id="同步阻塞I-O"><a href="#同步阻塞I-O" class="headerlink" title="同步阻塞I/O"></a>同步阻塞I/O</h3><p>阻塞I/O下请求无法立即完成则保持阻塞，阻塞I/O分为如下两个阶段。</p><p>阶段1：等待数据就绪。网络I/O的情况就是等待远端数据陆续抵达，也就是网络数据被复制到内核缓存区中，磁盘I/O的情况就是等待磁盘数据从磁盘上读取到内核态内存中。</p><p>阶段2：数据拷贝。出于系统安全，用户态的程序没有权限直接读取内核态内存，因此内核负责把内核态内存中的数据拷贝一份到用户态内存中。</p><p>这两个阶段必须都完成后才能继续下一步操作</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-19.png" alt=""></p><p><strong>所以，blocking IO的特点就是在IO执行的两个阶段都被block了。</strong></p><h3 id="同步非阻塞I-O"><a href="#同步非阻塞I-O" class="headerlink" title="同步非阻塞I/O"></a>同步非阻塞I/O</h3><p>就是阶段1的时候用户进程可选择做其他事情，通过轮询的方式看看内核缓冲区是否就绪。如果数据就绪，再去执行阶段2。</p><p>也就是说非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好， 此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。</p><p>重复上面的过程， 循环往复的进行recvform系统调用。这个过程通常被称之为轮询。轮询检查内核数据，直到数据准备好， 再拷贝数据到进程，进行数据处理。需要注意，第2阶段的拷贝数据整个过程，进程仍然是属于阻塞的状态。推荐阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;mid=2247488043&amp;idx=2&amp;sn=47c741acdfb93bd640c1a00fc9f4e30a&amp;chksm=eb53971ddc241e0b78126936b372bc3cea835ae2f492978220ac6006324121346eb45fcfad4e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Java 8 开发的 4 大顶级技巧</a></p><p>在linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程如图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-20.png" alt=""></p><p><strong>所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。</strong></p><h3 id="I-O多路复用"><a href="#I-O多路复用" class="headerlink" title="I/O多路复用"></a>I/O多路复用</h3><p>我这里只想重点解释一下I/O多路复用这种模型，因为现在用的最多。很多地方也称为事件驱动IO模型，只是叫法不同，意思都一个样。</p><p>IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。</p><p>目前支持I/O多路复用的系统调用有 select、pselect、poll、epoll，I/O多路复用就是通过一种机制，一个进程可以监视多个描述符， 一旦某个文件描述符fd就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。 </p><p>但select、pselect、poll、epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的， 而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。</p><p>相比较于同步非阻塞I/O，它的改进的地方在于，原来需要用户进程去轮询的这事儿交给了内核线程帮你完成， 而且这个内核线程可以等待多个socket，能实现同时对多个IO端口进行监听。</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-21.png" alt=""></p><p><strong>多路复用的特点是通过一种机制一个进程能同时等待IO文件描述符，内核监视这些文件描述符（套接字描述符）， 其中的任意一个进入读就绪状态，select， poll，epoll函数就可以返回。对于监视的方式， 又可以分为 select， poll， epoll三种方式。</strong></p><p>所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用多线程 + 阻塞IO的web server性能更好，可能延迟还更大。 也就是说，select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。推荐阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;mid=2247488058&amp;idx=1&amp;sn=42790c25bb1a5837f50724bc8c4fc991&amp;chksm=eb53970cdc241e1abd822910d3dfdf7bbdf41ee14d5e50e5bd85a3a7d05b864a4db4446a695c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Spring Boot 的 10 个核心模块</a></p><p>高并发的程序一般使用同步非阻塞方式而非多线程 + 同步阻塞方式。要理解这一点，首先要扯到并发和并行的区别。 比如去某部门办事需要依次去几个窗口，办事大厅里的人数就是并发数，而窗口个数就是并行度。 也就是说并发数是指同时进行的任务数（如同时服务的 HTTP 请求），而并行数是可以同时工作的物理资源数量（如 CPU 核数）。 </p><p>通过合理调度任务的不同阶段，并发数可以远远大于并行度，这就是区区几个 CPU 可以支持上万个用户并发请求的奥秘。 在这种高并发的情况下，为每个任务（用户请求）创建一个进程或线程的开销非常大。而同步非阻塞方式可以把多个 IO 请求丢到后台去， 这就可以在一个进程里服务大量的并发 IO 请求。</p><p><strong>IO多路复用归为同步阻塞模式</strong></p><h3 id="异步非阻塞-IO"><a href="#异步非阻塞-IO" class="headerlink" title="异步非阻塞 IO"></a>异步非阻塞 IO</h3><p>相对于同步IO，异步IO不是顺序执行。用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程， 然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段， 进程都是非阻塞的。</p><p>Linux提供了AIO库函数实现异步，但是用的很少。目前有很多开源的异步IO库，例如libevent、libev、libuv。异步过程如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-22.png" alt=""></p><h2 id="Java中四种I-O模型"><a href="#Java中四种I-O模型" class="headerlink" title="Java中四种I/O模型"></a>Java中四种I/O模型</h2><p>上一章所述Unix中的五种I/O模型，除信号驱动I/O外，Java对其它四种I/O模型都有所支持。</p><ol><li>Java传统IO模型即是同步阻塞I/O</li><li>NIO是同步非阻塞I/O</li><li>通过NIO实现的Reactor模式即是I/O多路复用模型的实现</li><li>通过AIO实现的Proactor模式即是异步I/O模型的实现</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> IO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>零拷贝技术sendfile</title>
      <link href="/posts/d3d.html"/>
      <url>/posts/d3d.html</url>
      
        <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在了解零拷贝之前，我们先来看看标准的的I/O操作..</p><p><strong>1.传统IO的原理</strong><br> 标准 I/O又被称作缓存 I/O ，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-14.png" alt="传统IO的原理"></p><p>缓存 I/O 有以下这些优点：</p><ul><li>缓存 I/O 使用了操作系统内核缓冲区，在一定程度上分离了应用程序空间和实际的物理设备。</li><li>缓存 I/O 可以减少读盘的次数，从而提高性能。</li></ul><p>当应用程序尝试读取某块数据的时候，如果这块数据已经存放在了内核的缓冲区中，那么这块数据就可以立即返回给应用程序，而不需要经过实际的物理读盘操作。当然，如果数据在应用程序读取之前并未被存放在内核的缓冲区中，那么就需要先将数据从磁盘读到页缓存中去。</p><p>对于写操作来说，应用程序也会将数据先写到内核的缓冲区中去，数据是否被立即写到磁盘上去取决于应用程序所采用的写操作机制：<br> 如果用户采用的是同步写机制（ synchronous writes ）, 那么数据会立即被写回到磁盘上，应用程序会一直等到数据被写完为止；<br> 如果用户采用的是延迟写机制（ deferred writes ），那么应用程序就完全不需要等到数据全部被写回到磁盘，数据只要被写到页缓存中(内核的缓冲区)去就可以了。在延迟写机制的情况下，操作系统会定期地将放在页缓存中的数据刷到磁盘上。与异步写机制（ asynchronous writes ）不同的是，延迟写机制在数据完全写到磁盘上的时候不会通知应用程序，而异步写机制在数据完全写到磁盘上的时候是会返回给应用程序的。所以延迟写机制本身是存在数据丢失的风险的，而异步写机制则不会有这方面的担心。</p><p><strong>2.传统IO的缺点</strong><br> 在缓存 I/O 机制中，DMA 方式可以将数据直接从磁盘读到页缓存中，或者将数据从页缓存直接写回到磁盘上，而不能直接在应用程序地址空间和磁盘之间进行数据传输，这样的话，数据在传输过程中需要在应用程序地址空间和页缓存之间进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。</p><p>当然也可以采用直接 I/O 技术来满足自缓存应用程序（ self-caching applications）的需求。<br>具体描述可以看这篇博客：<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.ibm.com%2Fdeveloperworks%2Fcn%2Flinux%2Fl-cn-directio%2Findex.html" target="_blank" rel="noopener">Linux 中直接 I/O 机制的介绍</a></p><h3 id="一-为什么需要零拷贝技术"><a href="#一-为什么需要零拷贝技术" class="headerlink" title="一.为什么需要零拷贝技术?"></a>一.为什么需要零拷贝技术?</h3><p>如今，很多网络服务器都是基于客户端 - 服务器这一模型的。在这种模型中，客户端向服务器端请求数据或者服务；服务器端则需要响应客户端发出的请求，并为客户端提供它所需要的数据。随着网络服务的逐渐普及，video 这类应用程序发展迅速。当今的计算机系统已经具备足够的能力去处理 video 这类应用程序对客户端所造成的重负荷，但是对于服务器端来说，它应付由 video 这类应用程序引起的网络通信量就显得捉襟见肘了。而且，客户端的数量增长迅速，那么服务器端就更容易成为性能瓶颈。而对于负荷很重的服务器来说，操作系统通常都是引起性能瓶颈的罪魁祸首。举个例子来说，当数据“写”操作或者数据“发送”操作的系统调用发出时，操作系统通常都会将数据从应用程序地址空间的缓冲区拷贝到操作系统内核的缓冲区中去。操作系统这样做的好处是接口简单，但是却在很大程度上损失了系统性能，因为这种数据拷贝操作不单需要占用 CPU 时间片，同时也需要占用额外的内存带宽。</p><p>一般来说，客户端通过网络接口卡向服务器端发送请求，操作系统将这些客户端的请求传递给服务器端应用程序，服务器端应用程序会处理这些请求，请求处理完成以后，操作系统还需要将处理得到的结果通过网络适配器传递回去。</p><h3 id="二-什么是零拷贝技术？"><a href="#二-什么是零拷贝技术？" class="headerlink" title="二.什么是零拷贝技术？"></a>二.什么是零拷贝技术？</h3><p>简单一点来说，零拷贝就是一种避免 CPU 将数据从一块存储拷贝到另外一块存储的技术。</p><p>零拷贝技术可以减少数据拷贝和共享总线操作的次数，消除传输数据在存储器之间不必要的中间拷贝次数，从而有效地提高数据传输效率。</p><p>而且，零拷贝技术减少了用户应用程序地址空间和操作系统内核地址空间之间因为上下文切换而带来的开销。进行大量的数据拷贝操作其实是一件简单的任务，从操作系统的角度来说，如果 CPU 一直被占用着去执行这项简单的任务，那么这将会是很浪费资源的；如果有其他比较简单的系统部件可以代劳这件事情，从而使得 CPU 解脱出来可以做别的事情，那么系统资源的利用则会更加有效。</p><p><strong>零拷贝技术的要点：</strong></p><ul><li>避免操作系统内核缓冲区之间进行数据拷贝操作。</li><li>避免操作系统内核和用户应用程序地址空间这两者之间进行数据拷贝操作。</li><li>用户应用程序可以避开操作系统直接访问硬件存储。</li><li>数据传输尽量让 DMA 来做。</li></ul><p>DMA：是指外部设备不通过CPU而直接与系统内存交换数据的接口技术。</p><p><strong>零拷贝技术分类</strong><br> Linux 中的零拷贝技术主要有下面这几种：</p><ul><li>直接 I/O</li><li>mmap</li><li>sendfile</li><li>splice</li></ul><p>本文主要介绍sendfile这种零拷贝技术..</p><h3 id="三-sendfile实现零拷贝的原理"><a href="#三-sendfile实现零拷贝的原理" class="headerlink" title="三.sendfile实现零拷贝的原理"></a>三.sendfile实现零拷贝的原理</h3><p><strong>1.描述</strong><br> sendfile系统调用在两个文件描述符之间直接传递数据(完全在内核中操作)，从而避免了数据在内核缓冲区和用户缓冲区之间的拷贝，操作效率很高，被称之为零拷贝。</p><p><strong>2.原理</strong><br> sendfile() 系统调用利用 DMA 引擎将文件中的数据拷贝到操作系统内核缓冲区中，然后数据被拷贝到与 socket 相关的内核缓冲区中去。接下来，DMA 引擎将数据从内核 socket 缓冲区中拷贝到协议引擎中去。</p><p>sendfile() 系统调用不需要将数据拷贝或者映射到应用程序地址空间中去，所以 sendfile() 只是<strong>适用于应用程序地址空间不需要对所访问数据进行处理</strong>的情况。因为 sendfile 传输的数据没有越过用户应用程序 / 操作系统内核的边界线，所以 sendfile () 也极大地减少了存储管理的开销。</p><p>简单归纳上述的过程：</p><ul><li>sendfile系统调用利用DMA引擎将文件数据拷贝到内核缓冲区，之后数据被拷贝到内核socket缓冲区中</li><li>DMA引擎将数据从内核socket缓冲区拷贝到协议引擎中</li></ul><p>这里没有用户态和内核态之间的切换，也没有内核缓冲区和用户缓冲区之间的拷贝，大大提升了传输性能。</p><h3 id="四-带有-DMA-收集拷贝功能的-sendfile"><a href="#四-带有-DMA-收集拷贝功能的-sendfile" class="headerlink" title="四.带有 DMA 收集拷贝功能的 sendfile"></a>四.带有 DMA 收集拷贝功能的 sendfile</h3><p>上面介绍的 sendfile() 技术在进行数据传输仍然还需要一次多余的数据拷贝操作，通过引入一点硬件上的帮助，这仅有的一次数据拷贝操作也可以避免。为了避免操作系统内核造成的数据副本，需要用到一个<strong>支持收集操作的网络接口</strong>。主要的方式是待传输的数据可以分散在存储的不同位置上，而不需要在连续存储中存放。这样一来，从文件中读出的数据就根本不需要被拷贝到 socket 缓冲区中去，而只是需要将缓冲区描述符传到网络协议栈中去，之后其在缓冲区中建立起数据包的相关结构，然后通过 DMA 收集拷贝功能将所有的数据结合成一个网络数据包。网卡的 DMA 引擎会在一次操作中从多个位置读取包头和数据。Linux 2.4 版本中的 socket 缓冲区就可以满足这种条件，这种方法不但减少了因为多次上下文切换所带来开销，同时也减少了处理器造成的数据副本的个数。对于用户应用程序来说，代码没有任何改变。</p><p><strong>主要过程如下：</strong><br> 首先，sendfile() 系统调用利用 DMA 引擎将文件内容拷贝到内核缓冲区去；然后，将带有文件位置和长度信息的缓冲区描述符添加到 socket 缓冲区中去，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，DMA 引擎会将数据直接从内核缓冲区拷贝到协议引擎中去，这样就避免了最后一次数据拷贝。</p><h3 id="五-总结"><a href="#五-总结" class="headerlink" title="五.总结"></a>五.总结</h3><p>上述的两种几种I/O操作对比：</p><p><strong>1.传统I/O</strong><br> 硬盘—&gt;内核缓冲区—&gt;用户缓冲区—&gt;内核socket缓冲区—&gt;协议引擎</p><p><strong>2.sendfile</strong><br> 硬盘—&gt;内核缓冲区—&gt;内核socket缓冲区—&gt;协议引擎</p><p><strong>3.sendfile（ DMA 收集拷贝）</strong><br> 硬盘—&gt;内核缓冲区—&gt;协议引擎</p><hr><p><strong>Tips:用户态和内核态切换的代价在哪？</strong></p><p>首先，用户态一个进程，内核态一个进程，切换就要进行进程间的切换。<br> 拿系统调用举例来说，系统调用一般都需要保存用户程序得上下文(context), 在进入内核得时候需要保存用户态得寄存器，在内核态返回用户态得时候会恢复这些寄存器得内容。这是一个开销的地方。</p><p>如果需要在不同用户程序间切换的话，那么还要更新cr3寄存器，这样会更换每个程序的虚拟内存到物理内存映射表的地址，也是一个比较高负担的操作。</p><p>而且内核代码对用户不信任，需要进行额外的检查。系统调用的返回过程有很多额外工作，比如检查是否需要调度等。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka为什么这么快？</title>
      <link href="/posts/4129.html"/>
      <url>/posts/4129.html</url>
      
        <content type="html"><![CDATA[<p>Kafka的消息是保存或缓存在磁盘上的，一般认为在磁盘上读写数据是会降低性能的，因为寻址会比较消耗时间，但是实际上，Kafka的特性之一就是高吞吐率。</p><p>即使是普通的服务器，Kafka也可以轻松支持每秒百万级的写入请求，超过了大部分的消息中间件，这种特性也使得Kafka在日志处理等海量数据场景广泛应用。</p><p>针对Kafka的基准测试可以参考，Apache Kafka基准测试：每秒写入2百万（在三台廉价机器上）</p><p>下面从数据写入和读取两方面分析，为什么为什么Kafka速度这么快。</p><h3 id="写入数据"><a href="#写入数据" class="headerlink" title="写入数据"></a><strong>写入数据</strong></h3><p>Kafka会把收到的消息都写入到硬盘中，它绝对不会丢失数据。为了优化写入速度Kafka采用了两个技术， 顺序写入 和 MMFile 。</p><h4 id="顺序写入"><a href="#顺序写入" class="headerlink" title="顺序写入"></a><strong>顺序写入</strong></h4><p>磁盘读写的快慢取决于你怎么使用它，也就是顺序读写或者随机读写。在顺序读写的情况下，某些优化场景磁盘的读写速度可以和内存持平（注：此处有疑问， 不推敲细节，参考 <a href="http://searene.me/2017/07/09/Why-is-Kafka-so-fast/" target="_blank" rel="noopener">http://searene.me/2017/07/09/Why-is-Kafka-so-fast/</a><br>）。</p><p>因为硬盘是机械结构，每次读写都会寻址-&gt;写入，其中寻址是一个“机械动作”，它是最耗时的。所以硬盘最讨厌随机I/O，最喜欢顺序I/O。为了提高读写硬盘的速度，Kafka就是使用顺序I/O。</p><p>而且Linux对于磁盘的读写优化也比较多，包括read-ahead和write-behind，磁盘缓存等。如果在内存做这些操作的时候，一个是JAVA对象的内存开销很大，另一个是随着堆内存数据的增多，JAVA的GC时间会变得很长，使用磁盘操作有以下几个好处：</p><ul><li><p>磁盘顺序读写速度超过内存随机读写</p></li><li><p>JVM的GC效率低，内存占用大。使用磁盘可以避免这一问题</p></li><li><p>系统冷启动后，磁盘缓存依然可用</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-12.png" alt=""></p><p>上图就展示了<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;mid=2247489678&amp;idx=1&amp;sn=72ad891e2e95ac7ce6d684bfe2184670&amp;chksm=eb539db8dc2414ae4da59185c54a9309ed3c65a436d0bfc0d4d862805dff266bcf84048029b2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Kafka</a>是如何写入数据的， 每一个Partition其实都是一个文件 ，收到消息后Kafka会把数据插入到文件末尾（虚框部分）。</p><p>这种方法有一个缺陷—— 没有办法删除数据 ，所以Kafka是不会删除数据的，它会把所有的数据都保留下来，每个消费者（Consumer）对每个Topic都有一个offset用来表示 读取到了第几条数据 。</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-13.png" alt=""></p><p>两个消费者，Consumer1有两个offset分别对应Partition0、Partition1（假设每一个Topic一个Partition）；Consumer2有一个offset对应Partition2。这个offset是由客户端SDK负责保存的，Kafka的Broker完全无视这个东西的存在；一般情况下SDK会把它保存到zookeeper里面。(所以需要给Consumer提供zookeeper的地址)。</p><p>如果不删除硬盘肯定会被撑满，所以Kakfa提供了两种策略来删除数据。一是基于时间，二是基于partition文件大小。具体配置可以参看它的配置文档。</p><h4 id="Memory-Mapped-Files"><a href="#Memory-Mapped-Files" class="headerlink" title="Memory Mapped Files"></a><strong>Memory Mapped Files</strong></h4><p>即便是顺序写入硬盘，硬盘的访问速度还是不可能追上内存。所以Kafka的数据并 不是实时的写入硬盘 ，它充分利用了现代操作系统 分页存储 来利用内存提高I/O效率。</p><p>Memory Mapped Files(后面简称mmap)也被翻译成 内存映射文件 ，在64位操作系统中一般可以表示20G的数据文件，它的工作原理是直接利用操作系统的Page来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上（操作系统在适当的时候）。</p><p>通过mmap，进程像读写硬盘一样读写内存（当然是虚拟机内存），也不必关心内存的大小有虚拟内存为我们兜底。</p><p>使用这种方式可以获取很大的<a href="https://p90csgo.pw/posts/8c27.html" target="_blank" rel="noopener">I/O</a>提升， 省去了用户空间到内核空间 复制的开销（调用文件的read会把数据先放到内核空间的内存中，然后再复制到用户空间的内存中。）也有一个很明显的缺陷——不可靠， 写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。</p><p>Kafka提供了一个参数——producer.type来控制是不是主动flush，如果Kafka写入到mmap之后就立即flush然后再返回Producer叫 同步 (sync)；写入mmap之后立即返回Producer不调用flush叫 异步 (async)。</p><h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a><strong>读取数据</strong></h3><h3 id="Kafka在读取磁盘时做了哪些优化？"><a href="#Kafka在读取磁盘时做了哪些优化？" class="headerlink" title="Kafka在读取磁盘时做了哪些优化？"></a><strong>Kafka在读取磁盘时做了哪些优化？</strong></h3><h4 id="基于sendfile实现Zero-Copy"><a href="#基于sendfile实现Zero-Copy" class="headerlink" title="基于sendfile实现Zero Copy"></a>基于sendfile实现Zero Copy</h4><p>传统模式下，当需要对一个文件进行传输的时候，其具体流程细节如下：</p><ol><li>调用read函数，文件数据被copy到内核缓冲区</li><li>read函数返回，文件数据从内核缓冲区copy到用户缓冲区</li><li>write函数调用，将文件数据从用户缓冲区copy到内核与socket相关的缓冲区。</li><li>数据从socket缓冲区copy到相关协议引擎。</li></ol><p>以上细节是传统read/write方式进行网络文件传输的方式，我们可以看到，在这个过程当中，文件数据实际上是经过了四次copy操作：</p><blockquote><p> 硬盘—&gt;内核buf—&gt;用户buf—&gt;socket相关缓冲区—&gt;协议引擎</p></blockquote><p>而sendfile系统调用则提供了一种减少以上多次copy，提升文件传输性能的方法。<br>在内核版本2.1中，引入了sendfile系统调用，以简化网络上和两个本地文件之间的数据传输。sendfile的引入不仅减少了数据复制，还减少了上下文切换。</p><p>sendfile(socket, file, len);</p><p><strong>运行流程如下：</strong></p><ol><li>sendfile系统调用，文件数据被copy至内核缓冲区</li><li>再从内核缓冲区copy至内核中socket相关的缓冲区</li><li>最后再socket相关的缓冲区copy到协议引擎</li></ol><p>相较传统read/write方式，2.1版本内核引进的sendfile已经减少了内核缓冲区到user缓冲区，再由user缓冲区到socket相关缓冲区的文件copy，而在内核版本2.4之后，文件描述符结果被改变，sendfile实现了更简单的方式，再次减少了一次copy操作。</p><p>在apache，<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;mid=2247487632&amp;idx=1&amp;sn=e85e5174db089aa9ae60770fe3105a84&amp;chksm=eb5395a6dc241cb066e4650997a3b1e0dc703c8db5cfd0031168a98418e80257e958c0ed99d9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">nginx</a>，lighttpd等web服务器当中，都有一项sendfile相关的配置，使用sendfile可以大幅提升文件传输性能。</p><p>Kafka把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候Kafka直接把文件发送给消费者，配合mmap作为文件读写方式，直接把它传给sendfile。</p><h4 id="批量压缩"><a href="#批量压缩" class="headerlink" title="批量压缩"></a><strong>批量压缩</strong></h4><p>在很多情况下，系统的瓶颈不是CPU或磁盘，而是网络IO，对于需要在广域网上的数据中心之间发送消息的数据流水线尤其如此。进行数据压缩会消耗少量的CPU资源,不过对于kafka而言,网络IO更应该需要考虑。</p><ul><li>如果每个消息都压缩，但是压缩率相对很低，所以Kafka使用了批量压缩，即将多个消息一起压缩而不是单个消息压缩</li><li>Kafka允许使用递归的消息集合，批量的消息可以通过压缩的形式传输并且在日志中也可以保持压缩格式，直到被消费者解压缩</li><li>Kafka支持多种压缩协议，包括Gzip和Snappy压缩协议</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>Kafka速度的秘诀在于，它把所有的消息都变成一个批量的文件，并且进行合理的批量压缩，减少网络IO损耗，通过mmap提高I/O速度，写入数据的时候由于单个Partion是末尾添加所以速度最优；读取数据的时候配合sendfile直接暴力输出。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> bigdata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Apache Spark 3.0.0 正式版终于发布了，重要特性全面解析</title>
      <link href="/posts/18fa.html"/>
      <url>/posts/18fa.html</url>
      
        <content type="html"><![CDATA[<p>原计划在2019年年底发布的 Apache Spark 3.0.0 今天终于赶在下周二举办的 Spark Summit AI 会议之前正式发布了! Apache Spark 3.0.0 自2018年10月02日开发到目前已经经历了近21个月！这个版本的发布经历了两个预览版以及三次投票：</p><ul><li>2019年11月06日第一次预览版，参见Preview release of Spark 3.0[1]</li><li>2019年12月23日第二次预览版，参见Preview release of Spark 3.0[2]</li><li>2020年03月21日 [VOTE] Apache Spark 3.0.0 RC1[3]</li><li>2020年05月18日 [VOTE] Apache Spark 3.0 RC2[4]</li><li>2020年06月06日 [vote] Apache Spark 3.0 RC3[5]</li></ul><p>Apache Spark 3.0 增加了很多令人兴奋的新特性，包括动态分区修剪（Dynamic Partition Pruning）、自适应查询执行（Adaptive Query Execution）、加速器感知调度（Accelerator-aware Scheduling）、支持 Catalog 的数据源API（Data Source API with Catalog Supports）、SparkR 中的向量化（Vectorization in SparkR）、支持 Hadoop 3/JDK 11/Scala 2.12 等等。这个版本一共解决了 3400 多个 ISSUES。</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-2.png" alt=""><br>这 3400 多个 issues 在 Spark 各个组件的分布情况如下：</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-3.png" alt=""><br>Apache Spark 3.0.0 中主要特性如下：</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-4.png" alt=""><br>关于这些比较重要的特性我已经在 这个分类里面进行了介绍，感兴趣的同学可以去看看。下面我们来快速看看 Spark 3.0 比较重要的新特性吧。比较全面的可以到 Spark Release 3.0.0 这里看看。</p><h3 id="动态分区修剪（Dynamic-Partition-Pruning）"><a href="#动态分区修剪（Dynamic-Partition-Pruning）" class="headerlink" title="动态分区修剪（Dynamic Partition Pruning）"></a><strong>动态分区修剪（Dynamic Partition Pruning）</strong></h3><p>所谓的动态分区裁剪就是基于运行时（run time）推断出来的信息来进一步进行分区裁剪。举个例子，我们有如下的查询：</p><pre><code>SELECT * FROM dim_iteblog JOIN fact_iteblog ON (dim_iteblog.partcol = fact_iteblog.partcol) WHERE dim_iteblog.othercol &gt; 10</code></pre><p>假设 dim_iteblog 表的 dim_iteblog.othercol &gt; 10 过滤出来的数据比较少，但是由于之前版本的 Spark 无法进行动态计算代价，所以可能会导致 fact_iteblog 表扫描出大量无效的数据。有了动态分区裁减，可以在运行的时候过滤掉 fact_iteblog 表无用的数据。经过这个优化，查询扫描的数据大大减少，性能提升了 33 倍。</p><p>在 TPC-DS 基准测试中，102个查询中的60个得到2到18倍的加速。</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-5.png" alt=""></p><p>这个特性对应的 ISSUE 可以参见 SPARK-11150 和 SPARK-28888。过往记忆大数据公众号也在前段时间对这个特性进行了详细介绍，具体请参见<a href="http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650718656&amp;idx=1&amp;sn=57de5460e470cb9e475799b972576463&amp;chksm=887ddcb6bf0a55a0569c134bbfab39efd91fef01407df60c4e3681486856972b4e70c15a4b92&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">《Apache Spark 3.0 动态分区裁剪（Dynamic Partition Pruning）介绍》</a>和<a href="http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650718711&amp;idx=1&amp;sn=f35b18df40de865a9a29064f3ea8d45e&amp;chksm=887ddc81bf0a559776e59d08c69a17426d716df9061ca69e39a396f5c82737c216b4bc8eedfd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">《Apache Spark 3.0 动态分区裁剪（Dynamic Partition Pruning）使用》</a>。</p><h3 id="自适应查询执行（Adaptive-Query-Execution）"><a href="#自适应查询执行（Adaptive-Query-Execution）" class="headerlink" title="自适应查询执行（Adaptive Query Execution）"></a>自适应查询执行（Adaptive Query Execution）</h3><p>自适应查询执行（又称 Adaptive Query Optimisation 或者 Adaptive Optimisation）是对查询执行计划的优化，允许 Spark Planner 在运行时执行可选的执行计划，这些计划将基于运行时统计数据进行优化。</p><p>早在2015年，Spark 社区就提出了自适应执行的基本想法，在 Spark 的 DAGScheduler 中增加了提交单个 map stage 的接口，并且在实现运行时调整 shuffle partition 数量上做了尝试。但目前该实现有一定的局限性，在某些场景下会引入更多的 shuffle，即更多的 stage，对于三表在同一个 stage 中做 join 等情况也无法很好的处理；而且使用当前框架很难灵活地在自适应执行中实现其他功能，例如更改执行计划或在运行时处理倾斜的 join。所以该功能一直处于实验阶段，配置参数也没有在官方文档中提及。这个想法主要来自英特尔以及百度的大牛，具体参见 SPARK-9850，对应的文章可以参见 <a href="http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650720582&amp;idx=1&amp;sn=56b63e59bf14bb23b30b240748880502&amp;chksm=887dd430bf0a5d26efcb876a12082bd3e55137cf07da0a7cbd5c8c872fb0585d3f00774ff660&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">《Apache Spark SQL自适应执行实践》</a></p><p>而 Apache Spark 3.0 的 Adaptive Query Execution（AQE） 是基于 SPARK-9850 的思想而实现的，具体参见 SPARK-23128。SPARK-23128 的目标是实现一个灵活的框架以在 Spark SQL 中执行自适应执行，并支持在运行时更改 reducer 的数量。新的实现解决了前面讨论的所有限制，其他功能（如更改 join 策略和处理倾斜 join）将作为单独的功能实现，并作为插件在后面版本提供。</p><p>AQE 框架目前提供了三个功能：</p><ul><li>动态合并 shuffle partitions；</li><li>动态调整 join 策略；</li><li>动态优化倾斜的 join（skew joins）。</li></ul><p>基于没有统计数据的 1TB TPC-DS 基准，Spark 3.0 可以使 q77 的速度提高8倍，使 q5 的速度提高2倍，而对另外26个查询的速度提高1.1倍以上。可以通过设置 SQL 配置 spark.sql.adaptive=true 来启用 AQE，这个参数默认值为 false。</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-6.png" alt=""></p><h3 id="加速器感知调度（Accelerator-aware-Scheduling）"><a href="#加速器感知调度（Accelerator-aware-Scheduling）" class="headerlink" title="加速器感知调度（Accelerator-aware Scheduling）"></a>加速器感知调度（Accelerator-aware Scheduling）</h3><p>如今大数据和机器学习已经有了很大的结合，在机器学习里面，因为计算迭代的时间可能会很长，开发人员一般会选择使用 GPU、FPGA 或 TPU 来加速计算。在 <a href="http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650714983&amp;idx=1&amp;sn=bf081153b923e2fbf247e0e0f91018f1&amp;chksm=887dae11bf0a2707709033021da1b20a95b73fbeeda5928c3439b6f16b9af19c37a66fe82bd1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Apache Hadoop 3.1 版本里面已经开始内置原生支持 GPU 和 FPGA 了</a>。作为通用计算引擎的 Spark 肯定也不甘落后，来自 Databricks、NVIDIA、Google 以及阿里巴巴的工程师们正在为 Apache Spark 添加原生的 GPU 调度支持，该方案填补了 Spark 在 GPU 资源的任务调度方面的空白，有机地融合了大数据处理和 AI 应用，扩展了 Spark 在深度学习、信号处理和各大数据应用的应用场景。这项工作的 issue 可以在 SPARK-24615 里面查看，相关的 SPIP（Spark Project Improvement Proposals） 文档可以参见 SPIP: Accelerator-aware scheduling[6]</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-7.png" alt=""></p><p>目前 Apache Spark 支持的资源管理器 YARN 和 Kubernetes 已经支持了 GPU。为了让 Spark 也支持 GPUs，在技术层面上需要做出两个主要改变：</p><ul><li>在 cluster manager 层面上，需要升级 cluster managers 来支持 GPU。并且给用户提供相关 API，使得用户可以控制 GPU 资源的使用和分配。</li><li>在 Spark 内部，需要在 scheduler 层面做出修改，使得 scheduler 可以在用户 task 请求中识别 GPU 的需求，然后根据 executor 上的 GPU 供给来完成分配。</li></ul><p>因为让 Apache Spark 支持 GPU 是一个比较大的特性，所以项目分为了几个阶段。在 Apache Spark 3.0 版本，将支持在 standalone、 YARN 以及 Kubernetes 资源管理器下支持 GPU，并且对现有正常的作业基本没影响。对于 TPU 的支持、Mesos 资源管理器中 GPU 的支持、以及 Windows 平台的 GPU 支持将不是这个版本的目标。而且对于一张 GPU 卡内的细粒度调度也不会在这个版本支持；Apache Spark 3.0 版本将把一张 GPU 卡和其内存作为不可分割的单元。详情请参见公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650716525&amp;idx=1&amp;sn=b13631e06f322e0b6c1a10f7a584788b&amp;chksm=887da41bbf0a2d0db1b069abedf72fa239212e881b9636af1a04bf583f1164822fc1b81393fa&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">《Apache Spark 3.0 将内置支持 GPU 调度》</a>。</p><h3 id="Apache-Spark-DataSource-V2"><a href="#Apache-Spark-DataSource-V2" class="headerlink" title="Apache Spark DataSource V2"></a>Apache Spark DataSource V2</h3><p>Data Source API 定义如何从存储系统进行读写的相关 API 接口，比如 Hadoop 的 InputFormat/OutputFormat，Hive 的 Serde 等。这些 API 非常适合用户在 Spark 中使用 RDD 编程的时候使用。使用这些 API 进行编程虽然能够解决我们的问题，但是对用户来说使用成本还是挺高的，而且 Spark 也不能对其进行优化。为了解决这些问题，Spark 1.3 版本开始引入了 Data Source API V1，通过这个 API 我们可以很方便的读取各种来源的数据，而且 Spark 使用 SQL 组件的一些优化引擎对数据源的读取进行优化，比如列裁剪、过滤下推等等。</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-8.png" alt=""></p><p>Data Source API V1 为我们抽象了一系列的接口，使用这些接口可以实现大部分的场景。但是随着使用的用户增多，逐渐显现出一些问题：</p><ul><li>部分接口依赖 SQLContext 和 DataFrame</li><li>扩展能力有限，难以下推其他算子</li><li>缺乏对列式存储读取的支持</li><li>缺乏分区和排序信息</li><li>写操作不支持事务</li><li>不支持流处理</li></ul><p>为了解决 Data Source V1 的一些问题，从 Apache Spark 2.3.0 版本开始，社区引入了 Data Source API V2，在保留原有的功能之外，还解决了 Data Source API V1 存在的一些问题，比如不再依赖上层 API，扩展能力增强。Data Source API V2 对应的 ISSUE 可以参见 SPARK-15689。虽然这个功能在 Apache Spark 2.x 版本就出现了，但是不是很稳定，所以社区对 Spark DataSource API V2 的稳定性工作以及新功能分别开了两个 ISSUE：SPARK-25186 以及 SPARK-22386。Spark DataSource API V2 最终稳定版以及新功能将会随着年底和 Apache Spark 3.0.0 版本一起发布，其也算是 Apache Spark 3.0.0 版本的一大新功能。</p><p>更多关于 Apache Spark DataSource V2 的详细介绍请参见 <a href="http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650717658&amp;idx=1&amp;sn=722e060f32ea72415e180c19b98eb142&amp;chksm=887da0acbf0a29babfb7a9edae9f5a577b6073ce65e8c087b6a89fe6a6ac77d634fcfaa138fe&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Apache Spark DataSource V2 介绍及入门编程指南（上）</a> 和 <a href="http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650717658&amp;idx=1&amp;sn=722e060f32ea72415e180c19b98eb142&amp;chksm=887da0acbf0a29babfb7a9edae9f5a577b6073ce65e8c087b6a89fe6a6ac77d634fcfaa138fe&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Apache Spark DataSource V2 介绍及入门编程指南（下）</a> 两篇文章的介绍。</p><h3 id="丰富的-API-和功能"><a href="#丰富的-API-和功能" class="headerlink" title="丰富的 API 和功能"></a>丰富的 API 和功能</h3><p>为了满足新的用例并简化 Spark 应用程序的开发，Apache Spark 3.0 版本提供了新的功能并增强了现有的功能。</p><h4 id="增强的-pandas-UDF"><a href="#增强的-pandas-UDF" class="headerlink" title="增强的 pandas UDF"></a>增强的 pandas UDF</h4><p>Pandas UDF 最初是在 Spark 2.3 中引入的，用于扩展 PySpark 中 UDF 并将 pandas API 集成到 PySpark 应用程序中。但是，当添加更多 UDF 类型时，现有接口很难理解。为了解决这个问题，Spark 3.0 引入了带有 Python 类型提示的新 pandas UDF 接口。此版本增加了两种新的 pandas UDF 类型：iterator of series to iterator of series 和 iterator of multiple series to iterator of series，以及三个新的 pandas 函数 API：grouped map、map 和 co-grouped map。详细介绍可以参见过往记忆大数据的 Apache Spark 3.0 新的 Pandas UDF 及 Python Type Hints：<a href="https://www.iteblog.com/archives/9814.html。" target="_blank" rel="noopener">https://www.iteblog.com/archives/9814.html。</a></p><h4 id="一组完整的-join-hints"><a href="#一组完整的-join-hints" class="headerlink" title="一组完整的 join hints"></a>一组完整的 join hints</h4><p>尽管社区不断提高编译器的智能性，但不能保证编译器始终可以针对每种情况做出最佳决策。Join 算法的选择基于统计和启发式算法，当编译器无法做出最佳选择时，用户仍然可以使用 join hints 来影响优化器选择更好的计划。Apache Spark 3.0 通过添加新的 hints 扩展了现有的 join hints ：SHUFFLE_MERGE、SHUFFLE_HASH 和 SHUFFLE_REPLICATE_NL</p><h4 id="新的内置函数"><a href="#新的内置函数" class="headerlink" title="新的内置函数"></a>新的内置函数</h4><p>Scala API 中增了32个新的内置函数和高阶函数。在这些内置函数中，添加了一组针对 MAP 的特定内置函数[transform_key，transform_value，map_entries，map_filter，map_zip_with]，以简化对 MAP 数据类型的处理。</p><h3 id="增强的监控功能"><a href="#增强的监控功能" class="headerlink" title="增强的监控功能"></a>增强的监控功能</h3><p>Apache Spark 在监控方面也包含许多增强功能，这些功能使监控更加全面和稳定。这些增强的监控功能不会对性能产生重大影响。主要可以分为以下三个地方。</p><h4 id="重新设计-Structured-streaming-的-UI"><a href="#重新设计-Structured-streaming-的-UI" class="headerlink" title="重新设计 Structured streaming 的 UI"></a>重新设计 Structured streaming 的 UI</h4><p>Structured streaming 最初是在 Spark 2.0 中引入的。Spark 3.0 为监控这些流作业重新设计了 UI。这个新的 UI 提供了两组统计信息：</p><ul><li>已完成的流查询作业的聚合信息</li><li>流查询的详细统计信息，包括 Input Rate, Process Rate, Input Rows, Batch Duration, Operation Duration 等</li></ul><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-9.png" alt=""></p><h4 id="增强-EXPLAIN-命令"><a href="#增强-EXPLAIN-命令" class="headerlink" title="增强 EXPLAIN 命令"></a>增强 EXPLAIN 命令</h4><p>读取计划（Reading plans）对理解和调优查询非常重要。现有的解决方案看起来很混乱，每个算子的字符串表示可能非常宽，甚至可能被截断。Spark 3.0 版本使用一种新的格式化（FORMATTED）模式对其进行了增强，并且还提供了将计划转储到文件的功能。</p><h4 id="可观察的指标"><a href="#可观察的指标" class="headerlink" title="可观察的指标"></a>可观察的指标</h4><p>连续监视数据质量的变化是管理数据管道非常需要的特性。Spark 3.0 版本为批处理和流处理应用程序引入了这种功能。可观察指标被命名为可以在查询上定义的任意聚合函数(dataframe)。一旦 dataframe 的执行到达一个完成点（例如，完成批查询），就会发出一个命名事件，其中包含自上一个完成点以来处理的数据的指标。</p><h3 id="更好的-ANSI-SQL-兼容"><a href="#更好的-ANSI-SQL-兼容" class="headerlink" title="更好的 ANSI SQL 兼容"></a>更好的 ANSI SQL 兼容</h3><p>PostgreSQL 是最先进的开源数据库之一，其支持 SQL:2011 的大部分主要特性，完全符合 SQL:2011 要求的 179 个功能中，PostgreSQL 至少符合 160 个。Spark 社区目前专门开了一个 ISSUE SPARK-27764 来解决 Spark SQL 和 PostgreSQL 之间的差异，包括功能特性补齐、Bug 修改等。功能补齐包括了支持 ANSI SQL 的一些函数、区分 SQL 保留关键字以及内置函数等。这个 ISSUE 下面对应了 231 个子 ISSUE，如果这部分的 ISSUE 都解决了，那么 Spark SQL 和 PostgreSQL 或者 ANSI SQL:2011 之间的差异更小了。</p><h3 id="SparkR-向量化读写"><a href="#SparkR-向量化读写" class="headerlink" title="SparkR 向量化读写"></a>SparkR 向量化读写</h3><p>Spark 是从 1.4 版本开始支持 R 语言的，但是那时候 Spark 和 R 进行交互的架构图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-10.png" alt=""></p><p>每当我们使用 R 语言和 Spark 集群进行交互，需要经过 JVM ，这也就无法避免数据的序列化和反序列化操作，这在数据量很大的情况下性能是十分低下的！</p><p>而且 Apache Spark 已经在许多操作中进行了向量化优化（vectorization optimization），例如，内部列式格式（columnar format）、Parquet/ORC 向量化读取、Pandas UDFs 等。向量化可以大大提高性能。SparkR 向量化允许用户按原样使用现有代码，但是当他们执行 R 本地函数或将 Spark DataFrame 与 R DataFrame 互相转换时，可以将性能提高大约数千倍。这项工作可以看下 SPARK-26759。新的架构如下:</p><p><img src="https://cdn.jsdelivr.net/gh/virgillone/cdn@master/medias/loading.gif" data-original="/images/pasted-11.png" alt=""></p><p>可以看出，SparkR 向量化是利用 Apache Arrow，其使得系统之间数据的交互变得很高效，而且避免了数据的序列化和反序列化的消耗，所以采用了这个之后，SparkR 和 Spark 交互的性能得到极大提升。</p><h3 id="Kafka-Streaming-includeHeaders"><a href="#Kafka-Streaming-includeHeaders" class="headerlink" title="Kafka Streaming: includeHeaders"></a>Kafka Streaming: includeHeaders</h3><p>Apache Kafka 0.11.0.0 版本支持在消息中配置一些 headers 信息，具体参见 KIP-82 - Add Record Headers，对应的 ISSUE 参见 KAFKA-4208。这些 Headers 在一些场景下很有用，Spark 3.0.0 为了满足用户的场景所以当然需要支持这个功能了，具体参见 SPARK-23539。具体使用如下</p><pre><code>val df = spark             .readStream             .format("kafka")             .option("kafka.bootstrap.servers", "host1:port1,host2:port2")             .option("subscribe", "topic1")            .option("includeHeaders", "true")            .load()df.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)", "headers") .as[(String, String, Map)]</code></pre><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul><li>Spark on K8S：Spark 对 Kubernetes 的支持是从2.3版本开始的，Spark 2.4 得到提升，Spark 3.0 将会加入 Kerberos 以及资源动态分配的支持。</li><li>Remote Shuffle Service：当前的 Shuffle 有很多问题，比如弹性差、对 NodeManager 有很大影响，不适应云环境。为了解决上面问题，将会引入 Remote Shuffle Service，具体参见 SPARK-25299</li><li>支持 JDK 11：参见 SPARK-24417，之所以直接选择 JDK 11 是因为 JDK 8 即将达到 EOL（end of life），而 JDK9 和 JDK10 已经是 EOL，所以社区就跳过 JDK9 和 JDK10 而直接支持 JDK11。不过 Spark 3.0 预览版默认还是使用 JDK 1.8；</li><li>移除对 Scala 2.11 的支持，默认支持 Scala 2.12，具体参见 SPARK-26132</li><li>支持 Hadoop 3.2，具体参见 SPARK-23710，Hadoop 3.0 已经发布了2年了（<a href="http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650714645&amp;idx=1&amp;sn=2bd531f181d71c611d0edcdacefd0b81&amp;chksm=887daf63bf0a2675637fc34d47d7f549df23eacebd4c8a9691aa216db109b5a895139cb246e1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Apache Hadoop 3.0.0-beta1 正式发布，下一个版本(GA)即可在线上使用</a>），所以支持 Hadoop 3.0 也是自然的，不过 Spark 3.0 预览版默认还是使用 Hadoop 2.7.4。</li><li>移除 Python 2.x 的支持：早在 2019年6月社区就有相关的讨论关于在 Spark 3.0 移除对 Python 2 的支持，目前 Spark 3.0.0 默认支持 Python 3.x ，参见 SPARK-27884。</li><li>Spark Graph 支持 Cypher：Cypher 是流行的图查询语言，现在我们可以直接在 Spark 3.0 使用 Cypher。</li><li>Spark event logs 支持 Roll 了，参见 <a href="http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650719561&amp;idx=1&amp;sn=c0689221eb08c17950c982dd34815ee8&amp;chksm=887dd83fbf0a512905cc69c24e91b7682e3414567b43c14447ca7eaa4d27b9ced689c805217b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">《Spark 3.0 终于支持 event logs 滚动了》</a>。</li></ul><h4 id="引用链接"><a href="#引用链接" class="headerlink" title="引用链接"></a>引用链接</h4><p><code>[1]</code> Preview release of Spark 3.0: <em><a href="https://spark.apache.org/news/spark-3.0.0-preview.html" target="_blank" rel="noopener">https://spark.apache.org/news/spark-3.0.0-preview.html</a></em><br><code>[2]</code> Preview release of Spark 3.0: <em><a href="https://spark.apache.org/news/spark-3.0.0-preview2.html" target="_blank" rel="noopener">https://spark.apache.org/news/spark-3.0.0-preview2.html</a></em><br><code>[3]</code> [VOTE] Apache Spark 3.0.0 RC1: <em><a href="https://www.mail-archive.com/dev@spark.apache.org/msg25781.html" target="_blank" rel="noopener">https://www.mail-archive.com/dev@spark.apache.org/msg25781.html</a></em><br><code>[4]</code> [VOTE] Apache Spark 3.0 RC2: <em><a href="https://www.mail-archive.com/dev@spark.apache.org/msg26040.html" target="_blank" rel="noopener">https://www.mail-archive.com/dev@spark.apache.org/msg26040.html</a></em><br><code>[5]</code> [vote] Apache Spark 3.0 RC3: <em><a href="https://www.mail-archive.com/dev@spark.apache.org/msg26119.html" target="_blank" rel="noopener">https://www.mail-archive.com/dev@spark.apache.org/msg26119.html</a></em></p><p><code>[6]</code> <a href="https://spark.apache.org/releases/spark-release-3-0-0.html" target="_blank" rel="noopener">https://spark.apache.org/releases/spark-release-3-0-0.html</a></p><p><code>[7]</code> SPIP: Accelerator-aware scheduling: <em><a href="https://issues.apache.org/jira/secure/attachment/12960252/SPIP_%20Accelerator-aware%20scheduling.pdf" target="_blank" rel="noopener">https://issues.apache.org/jira/secure/attachment/12960252/SPIP_%20Accelerator-aware%20scheduling.pdf</a></em></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>手把手教你用-FastDFS-构建分布式文件管理系统</title>
      <link href="/posts/cdb7.html"/>
      <url>/posts/cdb7.html</url>
      
        <content type="html"><![CDATA[<script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>letter</title>
      <link href="/posts/fbb5.html"/>
      <url>/posts/fbb5.html</url>
      
        <content type="html"><![CDATA[<h1 id="这是写给陈怡宝的信"><a href="#这是写给陈怡宝的信" class="headerlink" title="这是写给陈怡宝的信"></a>这是写给陈怡宝的信</h1><p>asas</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> xxx </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
